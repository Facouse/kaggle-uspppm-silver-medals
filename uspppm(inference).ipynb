{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import gc\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.nn as nn\n",
    "from transformers import AutoConfig, AutoModel, AdamW, AutoTokenizer\n",
    "import sys\n",
    "import scipy\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import warnings\n",
    "import scipy.stats\n",
    "\n",
    "class CFG:\n",
    "    result_dir = '/home/xuming/workspace/pppm' # result dir\n",
    "    data_dir = '/home/xuming/workspace/us-patent-phrase-to-phrase-matching' # data dir\n",
    "    k_folds = 5 # k folds\n",
    "    n_jobs = 5 # n_jobs\n",
    "    seed = 42 # random seed\n",
    "    device = torch.cuda.is_available() # use cuda\n",
    "    print_freq = 100 # print frequency\n",
    "    \n",
    "    model_name = 'bert-for-patents' # model name  # electra-large / deberta-v3-large / funnel-large / bert-for-patents \n",
    "    base_epoch = 5 # epoch\n",
    "    batch_size = 32 # batch size\n",
    "    lr = 1e-5 # learning rate\n",
    "    seq_length = 200 # sequence length\n",
    "    max_grad_norm = 1 # gradient clipping\n",
    "    \n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(CFG.seed)\n",
    "\n",
    "\n",
    "class KFold(object):\n",
    "    \"\"\"\n",
    "    Group split by group_col\n",
    "    \"\"\"\n",
    "    def __init__(self, k_folds=10, flag_name='fold_flag'):\n",
    "        self.k_folds = k_folds # k folds\n",
    "        self.flag_name = flag_name # fold_flag\n",
    "\n",
    "    def group_split(self, train_df, group_col): \n",
    "        group_value = list(set(train_df[group_col])) # group value\n",
    "        group_value.sort() # sort\n",
    "        fold_flag = [i % self.k_folds for i in range(len(group_value))] # fold_flag\n",
    "        np.random.shuffle(fold_flag) # shuffle\n",
    "        train_df = train_df.merge(pd.DataFrame({group_col: group_value, self.flag_name: fold_flag}), how='left', on=group_col) # merge\n",
    "        return train_df\n",
    "\n",
    "def get_data():\n",
    "    train_df = pd.read_csv(CFG.data_dir + '/train.csv') # train data\n",
    "    train_df = KFold(CFG.k_folds).group_split(train_df, group_col='anchor') # kfold group split\n",
    "    titles = get_cpc_texts() # cpc texts\n",
    "    train_df = get_text(train_df, titles) # # train data get text\n",
    "    test_df = pd.read_csv(CFG.data_dir + '/test.csv') # test data\n",
    "    test_df['score'], test_df['fold_flag'] = 0, -1 # test fill score and fold_flag\n",
    "    test_df = get_text(test_df, titles) # # test data get text\n",
    "    print(train_df.shape, test_df.shape) # print shape\n",
    "    return train_df, test_df # return train and test data\n",
    "\n",
    "def get_text(df, titles):\n",
    "    df['anchor'] = df['anchor'].apply(lambda x:x.lower()) # anchor lower\n",
    "    df['target'] = df['target'].apply(lambda x:x.lower()) # target lower\n",
    "    # title\n",
    "    df['title'] = df['context'].map(titles)\n",
    "    df['title'] = df['title'].apply(lambda x:x.lower().replace(';', '').replace('  ',' ').strip())\n",
    "\n",
    "    df = df.join(df.groupby(['anchor', 'context']).target.agg(list).rename('gp_targets'), on=['anchor', 'context']) # group by anchor and context and get target_list\n",
    "    df['gp_targets'] = df.apply(lambda x: ', '.join([i for i in x['gp_targets'] if i != x['target']]), axis=1) # get gp_targets\n",
    "    df['text'] = df['anchor'] + '[SEP]' + df['target'] + '[SEP]'  + df['title'] + '[SEP]'  + df['gp_targets'] # anchor [SEP] target [SEP] title [SEP] gp_targets\n",
    "    return df\n",
    "\n",
    "def get_cpc_texts():\n",
    "    '''\n",
    "    get cpc texts\n",
    "    '''\n",
    "    # get cpc codes\n",
    "    contexts = []  \n",
    "    pattern = '[A-Z]\\d+'\n",
    "    for file_name in os.listdir(f'{CFG.data_dir}/cpc-data/CPCSchemeXML202105'):\n",
    "        result = re.findall(pattern, file_name)\n",
    "        if result:\n",
    "            contexts.append(result)\n",
    "    contexts = sorted(set(sum(contexts, []))) # all unique cpc codes\n",
    "    # like ['A01', 'A21', 'A22', 'A23', 'A24', 'A41', 'A42', 'A43', 'A44', 'A45']\n",
    "    \n",
    "    results = {}\n",
    "    for cpc in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'Y']:\n",
    "        with open(f'{CFG.data_dir}/cpc-data/CPCTitleList202202/cpc-section-{cpc}_20220201.txt') as f:\n",
    "            s = f.read()\n",
    "        # 总目录及其text 如 \"A\t\tHUMAN NECESSITIES\"\n",
    "        pattern = f'{cpc}\\t\\t.+' \n",
    "        result = re.findall(pattern, s)\n",
    "        pattern = \"^\"+pattern[:-2]\n",
    "        cpc_result = re.sub(pattern, \"\", result[0]) # 获取描述，如 'HUMAN NECESSITIES'\n",
    "\n",
    "        for context in [c for c in contexts if c[0] == cpc]:\n",
    "            pattern = f'{context}\\t\\t.+'\n",
    "            result = re.findall(pattern, s) # cpc code及其text 如 'A01\\t\\tAGRICULTURE; FORESTRY; ANIMAL HUSBANDRY; HUNTING; TRAPPING; FISHING'\n",
    "            pattern = \"^\"+pattern[:-2]\n",
    "            results[context] = cpc_result + \". \" + re.sub(pattern, \"\", result[0]) # 生成字典 like {'A01': 'HUMAN NECESSITIES. AGRICULTURE; FORESTRY; ANIMAL HUSBANDRY; HUNTING; TRAPPING; FISHING'}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatentDatasetV2(Dataset):\n",
    "    def __init__(self, meta_data: pd.DataFrame, tokenizer, extract_col='text'):\n",
    "        self.meta_data = meta_data.copy()  # meta_data\n",
    "        self.meta_data.reset_index(drop=True, inplace=True) # reset index\n",
    "        if tokenizer.sep_token != '[SEP]': \n",
    "            self.meta_data['text'] = self.meta_data['text'].apply(lambda x:x.replace('[SEP]', tokenizer.sep_token)) # replace [SEP] to tokenizer.sep_token\n",
    "            \n",
    "        self.text = self.meta_data[extract_col].values # text\n",
    "        self.batch_max_length = self.meta_data['batch_max_length'].values # target\n",
    "        self.tokenizer = tokenizer # tokenizer\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        seq = self.text[index] # seq\n",
    "        target = 1 # target\n",
    "        batch_max_len = self.batch_max_length[index] # batch_max_len\n",
    "\n",
    "        encoded = self.tokenizer.encode_plus(\n",
    "            text=seq, # text\n",
    "            add_special_tokens=True, # add_special_tokens\n",
    "            max_length=min(batch_max_len, 512), # max_length\n",
    "            padding='max_length', # padding\n",
    "            return_attention_mask=True, # return_attention_mask\n",
    "            return_tensors='pt', # return_tensors\n",
    "            truncation=True # truncation\n",
    "        )\n",
    "        input_ids = encoded['input_ids'][0] # input_ids\n",
    "        attention_mask = encoded['attention_mask'][0] # attention_mask\n",
    "\n",
    "        # input_ids: torch.Size([32, 200]) # padding 为 0\n",
    "        # like tensor([[    2, 20211,  3269,  ...,     0,     0,     0],\n",
    "        #              [    2,  2785,  9669,  ...,     0,     0,     0]], device='cuda:0')\n",
    "\n",
    "        # attention_mask: torch.Size([32, 200]) # padding 为 0，其余为1\n",
    "        # like tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
    "        #              [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n",
    "\n",
    "        # target: torch.Size([32])\n",
    "        # like tensor([0.2500, 0.5000, 0.5000, 0.5000, 0.5000, 0.2500, 0.5000, 0.2500, 0.0000,\n",
    "        #              0.0000, 0.5000, 0.0000, 0.5000, 0.5000, 0.2500, 0.2500, 0.5000, 0.5000,\n",
    "        #              0.0000, 0.0000, 0.2500, 0.5000, 0.0000, 0.0000, 0.5000, 0.2500, 0.7500,\n",
    "        #              0.2500, 0.2500, 1.0000, 0.7500, 0.5000], device='cuda:0')\n",
    "\n",
    "        return input_ids, attention_mask, np.array(target, dtype=np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.meta_data) # len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatentModel(nn.Module):\n",
    "    def __init__(self, name, num_classes=1, pretrained=True):\n",
    "        super(PatentModel, self).__init__()\n",
    "        self.config = AutoConfig.from_pretrained(name) # config\n",
    "        self.attention_probs_dropout_prob=0. # attention_probs_dropout_prob\n",
    "        self.hidden_dropout_prob=0. # hidden_dropout_prob\n",
    "        if pretrained:\n",
    "            self.encoder = AutoModel.from_pretrained(name, config=self.config) \n",
    "        else:\n",
    "            self.encoder = AutoModel.from_config(self.config)\n",
    "        in_dim = self.encoder.config.hidden_size # get hidden_size\n",
    "        self.last_fc = nn.Linear(in_dim, num_classes) # last_fc\n",
    "        torch.nn.init.normal_(self.last_fc.weight, std=0.02) # init last_fc\n",
    "        self.sig = nn.Sigmoid() # Sigmoid\n",
    "\n",
    "    def forward(self, seq, seq_mask):\n",
    "        x = self.encoder(seq, attention_mask=seq_mask)[\"last_hidden_state\"] # forward                       # torch.Size([32, 200, 1024])\n",
    "        x = torch.sum(x * seq_mask.unsqueeze(-1), dim=1) / torch.sum(seq_mask, dim=1).unsqueeze(-1) # mean  # torch.Size([32, 1024])\n",
    "        out = self.last_fc(x) # last_fc                                                                     # torch.Size([32, 1])\n",
    "        out = self.sig(out) # Sigmoid                                                                       # torch.Size([32, 1])\n",
    "        out = torch.squeeze(out)                                                                            # torch.Size([32])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_test_df(df, tokenizer, batch_size):\n",
    "    # input ids lengths list \n",
    "    input_lengths = [] \n",
    "    for text in df['text'].fillna(\"\").values:\n",
    "        length = len(tokenizer(text, add_special_tokens=True)['input_ids'])\n",
    "        input_lengths.append(length)\n",
    "    df['input_lengths'] = input_lengths\n",
    "    length_sorted_idx = np.argsort([-l for l in input_lengths])\n",
    "\n",
    "    # sort dataframe by lengths\n",
    "    sort_df = df.iloc[length_sorted_idx]\n",
    "    # calc max_len per batch\n",
    "    sorted_input_length = sort_df['input_lengths'].values # \n",
    "    batch_max_length = np.zeros_like(sorted_input_length) # zeros_like \n",
    "    # every batch\n",
    "    for i in range((len(sorted_input_length)//batch_size)+1):\n",
    "        batch_max_length[i*batch_size:(i+1)*batch_size] = np.max(sorted_input_length[i*batch_size:(i+1)*batch_size]) # max input length in every batch\n",
    "    sort_df['batch_max_length'] = batch_max_length\n",
    "    return sort_df, length_sorted_idx\n",
    "\n",
    "def get_model_path(model_name):\n",
    "    '''\n",
    "    get model path\n",
    "    '''\n",
    "    res = CFG.result_dir\n",
    "    if model_name in ['electra-base', 'electra-large']:\n",
    "        res += '/electra/' + model_name.split('-')[1] + '-discriminator'\n",
    "    elif model_name == 'deberta-v3-large':\n",
    "        res += '/deberta-v3-large/'\n",
    "    elif model_name == 'funnel-large':\n",
    "        res += '/funnel-large/'\n",
    "    elif model_name == 'bert-for-patents':\n",
    "        res += '/bert-for-patents/'\n",
    "    else:\n",
    "        raise ValueError(model_name)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import gc\n",
    "import time\n",
    "from transformers import BertTokenizer, RobertaTokenizerFast, AutoTokenizer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "CFG.batch_size = 32 # batch size\n",
    "CFG.n_jobs = 4 # n_jobs\n",
    "CFG.seq_length = 512 # seq_length\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" # TOKENIZERS_PARALLELISM\n",
    "\n",
    "def predict(model, data_loader):\n",
    "    # switch to evaluate mode\n",
    "    model.eval() # model\n",
    "    y_pred = []\n",
    "    for i, batch_data in enumerate(data_loader): # 载入每个batch的数据\n",
    "        batch_data = (t.cuda() for t in batch_data)\n",
    "        seq, seq_mask, _ = batch_data # seq, seq_mask, target\n",
    "        outputs = model(seq, seq_mask).detach().cpu().numpy() # outputs\n",
    "        y_pred.append(outputs)\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    return y_pred\n",
    "\n",
    "def get_preds(my_df, my_loader, my_model, model_path, model_name=''):\n",
    "    my_model.load_state_dict(torch.load(model_path)['state_dict']) # 载入模型\n",
    "    my_model = my_model.cuda()\n",
    "    with torch.no_grad():\n",
    "        y_pred = predict(my_model, my_loader) # 获得y_pred\n",
    "    return y_pred\n",
    "\n",
    "train_df, test_df = get_data() # 获得训练集和测试集\n",
    "ensemble_weight = [0.2, 0.6, 0.1, 0.1] \n",
    "    \n",
    "print('>> predicting...\\n')\n",
    "start = time.time()\n",
    "# -------------------- Model 1 --------------------\n",
    "model_name = 'bert-for-patents' # model_name\n",
    "tokenizer_path = get_model_path(model_name) # get_model_path\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path) # tokenizer\n",
    "\n",
    "sort_df, length_sorted_idx = get_sorted_test_df(test_df.copy(), tokenizer, batch_size=CFG.batch_size) # sort_df, length_sorted_idx\n",
    "test_dataset = PatentDatasetV2(sort_df, tokenizer) # test_dataset\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=CFG.batch_size, num_workers=CFG.n_jobs, drop_last=False, pin_memory=True) # test_loader\n",
    "\n",
    "res1 = []\n",
    "folds = range(CFG.k_folds)\n",
    "for fold in folds:\n",
    "    model = PatentModel(get_model_path(model_name), pretrained=False) # model\n",
    "    model_path = '/home/xuming/workspace/pppm/models/{}_fold{}_seed{}.pth.tar'.format(model_name, fold, 42) # model_path\n",
    "    print(model_path)\n",
    "    y_preds = get_preds(test_df, test_loader, model, model_path) # y_preds\n",
    "    y_preds = y_preds[np.argsort(length_sorted_idx)] # y_preds\n",
    "    res1.append(y_preds)\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "res1 = np.mean(res1, axis=0)\n",
    "\n",
    "# -------------------- Model 2 --------------------\n",
    "model_name = 'deberta-v3-large' # model_name\n",
    "tokenizer_path = get_model_path(model_name) # get_model_path\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path) # tokenizer\n",
    "\n",
    "sort_df, length_sorted_idx = get_sorted_test_df(test_df.copy(), tokenizer, batch_size=CFG.batch_size) # sort_df, length_sorted_idx\n",
    "test_dataset = PatentDatasetV2(sort_df, tokenizer) # test_dataset\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=CFG.batch_size, num_workers=CFG.n_jobs, drop_last=False, pin_memory=True) # test_loader\n",
    "res2 = []\n",
    "folds = range(CFG.k_folds)\n",
    "for fold in folds:\n",
    "    model = PatentModel(get_model_path(model_name), pretrained=False) # model\n",
    "    model_path = '/home/xuming/workspace/pppm/models/{}_fold{}_seed{}.pth.tar'.format(model_name, fold, 42) # model_path\n",
    "    print(model_path)\n",
    "    y_preds = get_preds(test_df, test_loader, model, model_path) # y_preds\n",
    "    y_preds = y_preds[np.argsort(length_sorted_idx)] # y_preds\n",
    "    res2.append(y_preds)\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "res2 = np.mean(res2, axis=0)\n",
    "\n",
    "# -------------------- Model 3 --------------------\n",
    "model_name = 'electra-large' # model_name\n",
    "tokenizer_path = get_model_path(model_name)# get_model_path\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path) # tokenizer\n",
    "\n",
    "sort_df, length_sorted_idx = get_sorted_test_df(test_df.copy(), tokenizer, batch_size=CFG.batch_size) # sort_df, length_sorted_idx\n",
    "test_dataset = PatentDatasetV2(sort_df, tokenizer) # test_dataset\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=CFG.batch_size, num_workers=CFG.n_jobs, drop_last=False, pin_memory=True) # test_loader\n",
    "res3 = []\n",
    "folds = range(CFG.k_folds)\n",
    "for fold in folds:\n",
    "    model = PatentModel(get_model_path(model_name), pretrained=False) # model\n",
    "    model_path = '/home/xuming/workspace/pppm/models/{}_fold{}_seed{}.pth.tar'.format(model_name, fold, 42) # model_path\n",
    "    print(model_path)\n",
    "    y_preds = get_preds(test_df, test_loader, model, model_path) # y_preds\n",
    "    y_preds = y_preds[np.argsort(length_sorted_idx)] # y_preds\n",
    "    res3.append(y_preds)\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "res3 = np.mean(res3, axis=0)\n",
    "\n",
    "# -------------------- Model 4 --------------------\n",
    "model_name = 'funnel-large' # model_name\n",
    "tokenizer_path = get_model_path(model_name) # get_model_path\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path) # tokenizer\n",
    "\n",
    "sort_df, length_sorted_idx = get_sorted_test_df(test_df.copy(), tokenizer, batch_size=CFG.batch_size) # sort_df, length_sorted_idx\n",
    "test_dataset = PatentDatasetV2(sort_df, tokenizer) # test_dataset\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=CFG.batch_size, num_workers=CFG.n_jobs, drop_last=False, pin_memory=True) # test_loader\n",
    "res4 = []\n",
    "folds = range(CFG.k_folds)\n",
    "for fold in folds:\n",
    "    model = PatentModel(get_model_path(model_name), pretrained=False) # model\n",
    "    model_path = '/home/xuming/workspace/pppm/models/{}_fold{}_seed{}.pth.tar'.format(model_name, fold, 42) # model_path\n",
    "    print(model_path)\n",
    "    y_preds = get_preds(test_df, test_loader, model, model_path) # y_preds\n",
    "    y_preds = y_preds[np.argsort(length_sorted_idx)] # y_preds\n",
    "    res4.append(y_preds)\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "res4 = np.mean(res4, axis=0)\n",
    "\n",
    "# ensemble\n",
    "res = [res1,res2,res3,res4]\n",
    "for i in range(len(res)):\n",
    "    res[i] = (res[i] - res[i].mean())/res[i].std()\n",
    "test_df['score'] = np.sum([res[i] * ensemble_weight[i] for i in range(len(res))], axis=0)\n",
    "test_df['score'] = (test_df['score'] - test_df['score'].mean()) /test_df['score'].std()\n",
    "\n",
    "# get submission\n",
    "print(test_df.shape)\n",
    "test_df[['id', 'score']].to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b79a61544c9a744d09395b396d14bdc3ab2980641b64ddb1c7bc6d7b892900a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
